# Big Data Pipeline - Deployment & Schedule

## ğŸš€ QUICK START

### **Deploy toÃ n bá»™ pipeline (Cháº¡y ngay + Auto schedule)**

```bash
# 1. Apply cáº£ 2 file (Job sáº½ cháº¡y ngay láº­p tá»©c)
kubectl apply -f spark/batch-pipeline-cronjob.yaml
kubectl apply -f spark/house-price-train-job.yaml

# 2. Xem job init Ä‘ang cháº¡y
kubectl get jobs -n spark
# OUTPUT:
# batch-pipeline-init   0/1   10s
# ml-train-init         0/1   8s

# 3. Xem logs real-time
kubectl logs -n spark -l job-name=batch-pipeline-init --tail=100 -f
kubectl logs -n spark -l job-name=ml-train-init --tail=100 -f

# 4. Verify CronJob Ä‘Ã£ Ä‘Æ°á»£c táº¡o
kubectl get cronjob -n spark
```

---

## ğŸ“… Cáº¤U HÃŒNH SCHEDULE

### **1. Batch Pipeline (Bronze â†’ Silver â†’ Gold)**

**File:** [batch-pipeline-cronjob.yaml](batch-pipeline-cronjob.yaml)

**Chá»©a 2 resources:**
- âœ… **Job `batch-pipeline-init`**: Cháº¡y **NGAY** khi apply (1 láº§n duy nháº¥t)
- â° **CronJob `batch-pipeline`**: Tá»± Ä‘á»™ng cháº¡y **má»—i 10 phÃºt** (`*/10 * * * *`)

**Workflow (2 bÆ°á»›c tuáº§n tá»±):**
1. **Bronze â†’ Silver:** Clean + Feature Engineering
   - 4 features: `price_per_sqft`, `house_age`, `total_rooms`, `condition_score`
   - Incremental processing: `pg-max-offset` dedup (chá»‰ xá»­ lÃ½ offset má»›i)
   - Output: MinIO `silver/` + PostgreSQL `fact_house`

2. **Silver â†’ Gold:** Aggregations
   - 4 báº£ng: `gold_location_stats`, `gold_condition_stats`, `gold_bedroom_analysis`, `gold_year_built_trends`
   - Output: MinIO `gold/` + PostgreSQL `gold_*` tables

**Thá»i gian cháº¡y:** ~1-2 phÃºt/láº§n

---

### **2. ML Training + Inference**

**File:** [house-price-train-job.yaml](house-price-train-job.yaml)

**Chá»©a 2 resources:**
- âœ… **Job `ml-train-init`**: Cháº¡y **NGAY** khi apply (1 láº§n duy nháº¥t)
- â° **CronJob `house-price-train`**: Tá»± Ä‘á»™ng cháº¡y **má»—i giá»** (`0 * * * *`)

**Workflow (2 bÆ°á»›c tuáº§n tá»±):**
1. **Train model** tá»« Silver data
   - Features: 4 original + 4 engineered + 2 categorical (OHE)
   - Model: Random Forest (50 trees, max depth 10)
   - Metrics: RMSE, RÂ²
   - Output: MinIO `models/house_price/latest` + PostgreSQL `ml_house_price_model_metrics`

2. **Inference** trÃªn toÃ n bá»™ Silver data
   - Predict giÃ¡ cho táº¥t cáº£ houses
   - Output: MinIO `gold/predictions_house_price/` + PostgreSQL `house_price_predictions`

**Thá»i gian cháº¡y:** ~5-10 phÃºt/láº§n

---

## â° TIMELINE DEPLOY

```
00:00:00 - kubectl apply (cáº£ 2 file)
00:00:02 - batch-pipeline-init báº¯t Ä‘áº§u (Job init)
00:00:03 - ml-train-init báº¯t Ä‘áº§u (Job init)
00:02:30 - batch-pipeline-init hoÃ n thÃ nh âœ“
00:08:45 - ml-train-init hoÃ n thÃ nh âœ“
00:10:00 - batch-pipeline CronJob cháº¡y láº§n 1 (auto)
00:20:00 - batch-pipeline CronJob cháº¡y láº§n 2 (auto)
01:00:00 - house-price-train CronJob cháº¡y láº§n 1 (auto)
...
```

**Táº§n suáº¥t cháº¡y má»—i ngÃ y:**
- Batch Pipeline: **144 láº§n** (má»—i 10 phÃºt)
- ML Train+Inference: **24 láº§n** (má»—i giá»)

---

## ğŸ”§ OPERATIONS

### **Xem logs**

```bash
# Logs cá»§a Job init (cháº¡y 1 láº§n)
kubectl logs -n spark -l job-name=batch-pipeline-init --tail=100
kubectl logs -n spark -l job-name=ml-train-init --tail=100

# Logs cá»§a CronJob (cháº¡y Ä‘á»‹nh ká»³)
kubectl logs -n spark -l job-name=batch-pipeline-28435440 --tail=100 -f
kubectl logs -n spark -l job-name=house-price-train-28435400 --tail=100 -f
```

### **Trigger thÃªm láº§n ná»¯a (manual)**

```bash
# Cháº¡y batch thÃªm 1 láº§n (khÃ´ng Ä‘á»£i schedule)
kubectl create job --from=cronjob/batch-pipeline batch-manual-$(date +%s) -n spark

# Cháº¡y ML train thÃªm 1 láº§n
kubectl create job --from=cronjob/house-price-train train-manual-$(date +%s) -n spark
```

### **Táº¡m dá»«ng CronJob**

```bash
# Suspend CronJob (khÃ´ng cháº¡y tá»± Ä‘á»™ng ná»¯a)
kubectl patch cronjob batch-pipeline -n spark -p '{"spec":{"suspend":true}}'
kubectl patch cronjob house-price-train -n spark -p '{"spec":{"suspend":true}}'

# Resume láº¡i
kubectl patch cronjob batch-pipeline -n spark -p '{"spec":{"suspend":false}}'
kubectl patch cronjob house-price-train -n spark -p '{"spec":{"suspend":false}}'
```

### **XÃ³a toÃ n bá»™**

```bash
# XÃ³a táº¥t cáº£ jobs vÃ  cronjobs
kubectl delete job batch-pipeline-init -n spark
kubectl delete job ml-train-init -n spark
kubectl delete cronjob batch-pipeline -n spark
kubectl delete cronjob house-price-train -n spark
kubectl delete configmap batch-pipeline-config -n spark
kubectl delete configmap spark-ml-train-jobs -n spark
```

---

## ğŸ¯ KIáº¾N TRÃšC PIPELINE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KAFKA PRODUCER                            â”‚
â”‚                   (house_data.json)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ Topic: data-stream
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   KAFKA CONSUMER                             â”‚
â”‚         Batch 200 msgs hoáº·c 3 phÃºt â†’ Bronze (JSONL)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MinIO: bronze/                            â”‚
â”‚      dt=YYYY-MM-DD/hour=HH/topic=*/partition=*/*.jsonl      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ [INIT: Cháº¡y ngay khi deploy]
                      â”‚ [AUTO: Má»—i 10 phÃºt]
                      â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   BATCH PIPELINE (Spark Job)       â”‚
         â”‚                                     â”‚
         â”‚  Step 1: Bronze â†’ Silver            â”‚
         â”‚  - Clean data                       â”‚
         â”‚  - Feature Engineering (4 features) â”‚
         â”‚  - Dedup (pg-max-offset)            â”‚
         â”‚                                     â”‚
         â”‚  Step 2: Silver â†’ Gold              â”‚
         â”‚  - 4 Aggregation Tables             â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  MinIO Silver/ â”‚               â”‚
         â”‚  (Parquet)     â”‚               â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
                  â”‚                       â”‚
                  â”‚ [INIT: Cháº¡y ngay]    â”‚
                  â”‚ [AUTO: Má»—i giá»]     â”‚
                  â–¼                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ML TRAIN + INFERENCE   â”‚   â”‚  MinIO Gold/     â”‚
    â”‚  - Random Forest        â”‚   â”‚  - location_*    â”‚
    â”‚  - RMSE, RÂ² metrics     â”‚   â”‚  - condition_*   â”‚
    â”‚  - Predict all houses   â”‚   â”‚  - bedroom_*     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  - year_trends_* â”‚
               â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                            â”‚
               â–¼                            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ MinIO models/      â”‚      â”‚   PostgreSQL        â”‚
    â”‚ - latest/          â”‚      â”‚  - fact_house       â”‚
    â”‚ - runs/{run_id}/   â”‚      â”‚  - gold_* (4 báº£ng)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  - ml_metrics       â”‚
                                â”‚  - predictions      â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â–¼
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚   DASHBOARD         â”‚
                                â”‚   (Streamlit)       â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ DATABASE SCHEMA (PostgreSQL)

### **Layer: Batch (from Spark)**

| Báº£ng | Cháº¿ Ä‘á»™ | Nguá»“n | MÃ´ táº£ |
|------|--------|-------|-------|
| `fact_house` | append | Silver job | Clean house data (cÃ³ topic, partition, offset Ä‘á»ƒ dedup) |

### **Layer: Gold (Aggregations)**

| Báº£ng | Cháº¿ Ä‘á»™ | Nguá»“n | MÃ´ táº£ |
|------|--------|-------|-------|
| `gold_location_stats` | overwrite | Gold job | Thá»‘ng kÃª theo location (avg_price, median, total_houses...) |
| `gold_condition_stats` | overwrite | Gold job | Thá»‘ng kÃª theo condition (Excellent, Good, Fair) |
| `gold_bedroom_analysis` | overwrite | Gold job | PhÃ¢n tÃ­ch theo sá»‘ bedrooms |
| `gold_year_built_trends` | overwrite | Gold job | Xu hÆ°á»›ng giÃ¡ theo decade (1980s, 1990s...) |

### **Layer: ML**

| Báº£ng | Cháº¿ Ä‘á»™ | Nguá»“n | MÃ´ táº£ |
|------|--------|-------|-------|
| `ml_house_price_model_metrics` | append | ML Train | RMSE, RÂ², run_id, model_path |
| `house_price_predictions` | append | ML Inference | actual_price vs predicted_price |

### **Layer: Speed (from Spark Streaming)**

| Báº£ng | Cháº¿ Ä‘á»™ | Nguá»“n | MÃ´ táº£ |
|------|--------|-------|-------|
| `house_data_speed` | append | Spark Streaming | Real-time data (5s latency) |

---

## âš™ï¸ RESOURCE REQUIREMENTS

### **Batch Pipeline**
- Memory: 2-4 GiB
- CPU: 1-2 cores
- Thá»i gian: ~1-2 phÃºt
- Spark mode: `local[*]`

### **ML Train + Inference**
- Memory: ~4 GiB (vá»›i packages download)
- CPU: 2+ cores
- Thá»i gian: ~5-10 phÃºt
- Dependencies: hadoop-aws, aws-java-sdk, postgresql, numpy

---

## ğŸ” TROUBLESHOOTING

### **Job init khÃ´ng cháº¡y hoáº·c failed**

```bash
# Kiá»ƒm tra job status
kubectl get jobs -n spark

# Xem lá»—i
kubectl describe job batch-pipeline-init -n spark
kubectl describe job ml-train-init -n spark

# Xem logs
kubectl logs -n spark -l job-name=batch-pipeline-init --tail=200
kubectl logs -n spark -l job-name=ml-train-init --tail=200
```

**Lá»—i thÆ°á»ng gáº·p:**
- âŒ Bronze folder empty â†’ ChÆ°a cÃ³ data tá»« Kafka Consumer
- âŒ PostgreSQL connection refused â†’ Postgres chÆ°a ready hoáº·c sai password
- âŒ MinIO 403 Forbidden â†’ Sai access key/secret key
- âŒ OutOfMemory â†’ TÄƒng `driver-memory` vÃ  `executor-memory`

### **CronJob khÃ´ng cháº¡y Ä‘Ãºng giá»**

```bash
# Kiá»ƒm tra schedule
kubectl get cronjob batch-pipeline -n spark -o yaml | grep schedule

# Xem láº§n cháº¡y cuá»‘i
kubectl get cronjob -n spark
# OUTPUT: LAST SCHEDULE column

# Xem history
kubectl get jobs -n spark --sort-by=.metadata.creationTimestamp
```

### **Data bá»‹ duplicate**

**NguyÃªn nhÃ¢n:** Dedup strategy khÃ´ng hoáº¡t Ä‘á»™ng

**Giáº£i phÃ¡p:**
```bash
# Kiá»ƒm tra báº£ng fact_house cÃ³ topic, partition, offset khÃ´ng
kubectl exec -it postgres-0 -n postgres -- psql -U postgres -d house_warehouse -c "SELECT topic, partition, MAX(offset) FROM fact_house GROUP BY topic, partition;"

# Náº¿u khÃ´ng cÃ³ â†’ Láº§n Ä‘áº§u cháº¡y cáº§n cÃ³ dá»¯ liá»‡u
# Náº¿u cÃ³ â†’ Kiá»ƒm tra pg-max-offset strategy trong logs
```

---

## ğŸ“ NOTES

- **Init Jobs** cháº¡y 1 láº§n khi deploy, khÃ´ng tá»± Ä‘á»™ng retry náº¿u fail (pháº£i deploy láº¡i)
- **CronJobs** cÃ³ `concurrencyPolicy: Forbid` â†’ KhÃ´ng cho 2 job cháº¡y cÃ¹ng lÃºc
- **Dedup strategy** `pg-max-offset` cáº§n PostgreSQL cÃ³ dá»¯ liá»‡u, láº§n Ä‘áº§u sáº½ process all
- **ML model** ghi Ä‘Ã¨ `latest/` má»—i láº§n train, nhÆ°ng archive vÃ o `runs/{run_id}/`
- **Gold tables** dÃ¹ng `overwrite` mode â†’ Recalculate toÃ n bá»™ má»—i láº§n cháº¡y

### **Thay Ä‘á»•i schedule ML training**
Edit [house-price-train-job.yaml](house-price-train-job.yaml):

```yaml
spec:
  schedule: "0 * * * *"  # Má»—i giá»
  # schedule: "0 */2 * * *"  # Má»—i 2 giá»
  # schedule: "0 0 * * *"  # Má»—i ngÃ y 00:00
  # schedule: "*/30 * * * *"  # Má»—i 30 phÃºt
```

### **Thay Ä‘á»•i ML hyperparameters**
Sá»­a env trong YAML:

```yaml
env:
  - name: RF_NUM_TREES
    value: "100"  # Default: 50
  - name: RF_MAX_DEPTH
    value: "15"   # Default: 10
  - name: ML_TRAIN_RATIO
    value: "0.85"  # Default: 0.8
```

---

## ğŸš€ DEPLOYMENT STEPS

### **Láº§n Ä‘áº§u deploy:**
```bash
# 1. Deploy ML CronJob
kubectl apply -f spark/house-price-train-job.yaml

# 2. Verify
kubectl get cronjob -n spark
kubectl get pods -n spark

# 3. (Optional) Trigger manual job
kubectl create job --from=cronjob/house-price-train house-price-train-first -n spark

# 4. Monitor
kubectl logs -f -n spark -l job-name=house-price-train-first
```

### **Update code:**
```bash
# Edit local files
vim spark/jobs/ml_train_house_price.py

# Re-apply ConfigMap + CronJob
kubectl apply -f spark/house-price-train-job.yaml

# Next scheduled run sáº½ dÃ¹ng code má»›i
```

---

## ğŸ“Š MONITORING

### **Check schedule**
```bash
kubectl get cronjob -n spark
```

### **Xem job history**
```bash
kubectl get jobs -n spark --sort-by=.metadata.creationTimestamp
```

### **Xem predictions trong PostgreSQL**
```sql
-- Latest predictions
SELECT run_id, COUNT(*) as total, AVG(ABS(actual_price - predicted_price)) as mae
FROM house_price_predictions
GROUP BY run_id
ORDER BY run_id DESC
LIMIT 10;

-- Model metrics
SELECT run_id, rmse, r2, as_of_utc
FROM ml_house_price_model_metrics
ORDER BY as_of_utc DESC
LIMIT 10;
```

---

## âœ… SUMMARY
 Files |
|-----------|-----------|--------|-------|-------|
| **Stream â†’ Bronze** | Real-time | Kafka Consumer | âœ… Auto | Bronze NDJSON |
| **Bronze â†’ Silver â†’ Gold** | 10 phÃºt 1 láº§n | CronJob | âœ… Auto | batch-pipeline-cronjob.yaml |
| **ML Train + Inference** | 1 giá» 1 láº§n | CronJob | âœ… Auto | house-price-train-job.yam Auto |
| **Silver â†’ Gold** | On-demand | Manual Job | âŒ Manual |

**Lá»£i Ã­ch:**
- âœ… Data pipeline gáº§n real-time (Bronzeâ†’Silver má»—i 10 phÃºt)
- âœ… Pipeline tá»± Ä‘á»™ng hoÃ n toÃ n: Bronze â†’ Silver â†’ Gold (má»—i 10 phÃºt)
- âœ… ML train sá»­ dá»¥ng features tá»« Silver (consistency giá»¯a train/inference)
- âœ… Features computed once á»Ÿ Silver layer, reuse á»Ÿ ML vÃ  Gold
- âœ… Batch window trÃ¡nh xá»­ lÃ½ láº¡i toÃ n bá»™ data
- âœ… Inference tá»± Ä‘á»™ng sau train â†’ Predictions luÃ´n fresh
ğŸ‰ **Pipeline Ä‘Ã£ sáºµn sÃ ng production!**
