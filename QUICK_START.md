# ğŸš€ QUICK START - Cháº¡y Song Song 2 Pipeline

Lambda Architecture: **Batch Layer + Speed Layer** cháº¡y Ä‘á»“ng thá»i

---

## ğŸ“‹ Prerequisites

- âœ… Minikube running (`minikube start`)
- âœ… kubectl configured
- âœ… Äang á»Ÿ thÆ° má»¥c root: `D:\2025.1\bigdata\btl_bigdata`

---

## ğŸ—ï¸ BÆ¯á»šC 1: Deploy Infrastructure (1 láº§n)

```powershell
# 1.1. MinIO
kubectl create namespace minio
kubectl apply -f minio/config_minio.yaml
kubectl wait --for=condition=Ready pod -l app=minio -n minio --timeout=90s

# 1.2. PostgreSQL
kubectl apply -f postgres/postgres.yaml
kubectl wait --for=condition=Ready pod -l app=postgres -n postgres --timeout=90s

# 1.3. Kafka
kubectl create namespace kafka
kubectl apply -f kafka/kafka.yaml
kubectl wait --for=condition=Ready pod/kafka-0 -n kafka --timeout=120s

# 1.4. Spark Runner
kubectl create namespace spark
kubectl apply -f spark/spark-runner.k8s.yaml
kubectl wait --for=condition=Ready pod/spark-runner -n spark --timeout=90s

# 1.5. Kafka Flow (Producer + Consumer + Spark Streaming)
kubectl apply -f kafka/flow.yaml
kubectl apply -f spark_streaming/spark-deployment.yaml
Start-Sleep -Seconds 30

# Verify
kubectl get pods -A | Select-String -Pattern "(kafka|minio|postgres|spark)"
```

**Expected: Táº¥t cáº£ pods `Running`**

---

## ğŸ”§ BÆ¯á»šC 2: Copy Code vÃ o Pods

```powershell
# 2.1. Producer
$POD_PRO = kubectl get pods -n kafka -l app=producer -o jsonpath='{.items[0].metadata.name}'
kubectl cp kafka/producer.py -n kafka "${POD_PRO}:/app/producer.py"
kubectl cp kafka/house_data.json -n kafka "${POD_PRO}:/app/house_data.json"

# 2.2. Consumer
$POD_CON = kubectl get pods -n kafka -l app=consumer -o jsonpath='{.items[0].metadata.name}'
kubectl cp kafka/consumer.py -n kafka "${POD_CON}:/app/consumer.py"
kubectl cp kafka/upload_to_storage.py -n kafka "${POD_CON}:/app/upload_to_storage.py"

# 2.3. Spark Streaming
$POD_STREAM = kubectl get pods -n kafka -l app=spark-streaming -o jsonpath='{.items[0].metadata.name}'
kubectl cp spark_streaming/stream.py -n kafka "${POD_STREAM}:/app/stream.py"

# 2.4. Spark Batch Jobs
kubectl exec -n spark spark-runner -- mkdir -p /opt/project/jobs
kubectl cp spark/jobs/common.py -n spark spark-runner:/opt/project/jobs/
kubectl cp spark/jobs/silver_job.py -n spark spark-runner:/opt/project/jobs/
kubectl cp spark/jobs/gold_job.py -n spark spark-runner:/opt/project/jobs/
kubectl cp spark/jobs/ml_train_house_price.py -n spark spark-runner:/opt/project/jobs/

Write-Host "âœ… Code copied!" -ForegroundColor Green
```

---

## ğŸ¯ BÆ¯á»šC 3: Táº¡o MinIO Bucket

```powershell
# Terminal riÃªng - Port-forward MinIO
kubectl -n minio port-forward svc/minio-public 9001:9001
```

**Má»Ÿ browser:**
- URL: `http://localhost:9001`
- Login: `minioadmin` / `minioadmin`
- Táº¡o bucket tÃªn: **`house-lake`**

---

## ğŸš€ BÆ¯á»šC 4: Cháº¡y Song Song 2 Pipeline

### Má» 4 TERMINAL POWERSHELL Má»šI:

---

### **TERMINAL 1: PRODUCER (Data Source)**

```powershell
cd D:\2025.1\bigdata\btl_bigdata
$POD_PRO = kubectl get pods -n kafka -l app=producer -o jsonpath='{.items[0].metadata.name}'
kubectl exec -it -n kafka $POD_PRO -- python /app/producer.py
```

**Output mong Ä‘á»£i:**
```
âœ“ Gá»­i thÃ nh cÃ´ng tá»›i data-stream [0] @ offset 0
âœ“ Gá»­i thÃ nh cÃ´ng tá»›i data-stream [0] @ offset 1
...
```

**Äá»‚ CHáº Y 1-2 PHÃšT** (gá»­i ~300-500 messages)

---

### **TERMINAL 2: CONSUMER (Batch Pipeline â†’ Bronze)**

```powershell
cd D:\2025.1\bigdata\btl_bigdata
$POD_CON = kubectl get pods -n kafka -l app=consumer -o jsonpath='{.items[0].metadata.name}'
kubectl exec -it -n kafka $POD_CON -- python /app/consumer.py
```

**Output mong Ä‘á»£i:**
```
âœ… [BRONZE] Uploaded 200 records -> s3://house-lake/bronze/dt=2026-01-16/...
âœ… [BRONZE] Uploaded 200 records -> s3://house-lake/bronze/dt=2026-01-16/...
```

**Äá»‚ CHáº Y cho Ä‘áº¿n khi tháº¥y Ã­t nháº¥t 2-3 batch uploaded**

---

### **TERMINAL 3: SPARK STREAMING (Speed Pipeline â†’ PostgreSQL)**

```powershell
cd D:\2025.1\bigdata\btl_bigdata
$POD_STREAM = kubectl get pods -n kafka -l app=spark-streaming -o jsonpath='{.items[0].metadata.name}'

kubectl exec -it -n kafka $POD_STREAM -- /bin/bash -c "mkdir -p /tmp/ivy2 && /opt/spark/bin/spark-submit --master local[2] --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.postgresql:postgresql:42.7.1 --conf spark.jars.ivy=/tmp/ivy2 /app/stream.py"
```

**Output mong Ä‘á»£i:**
```
ğŸš€ Khá»Ÿi Ä‘á»™ng Spark Streaming...
   Kafka: kafka-service.kafka.svc.cluster.local:9092
   PostgreSQL: jdbc:postgresql://postgres.postgres...
[Batch 0] ÄÃ£ ghi 15 records vÃ o PostgreSQL
[Batch 1] ÄÃ£ ghi 23 records vÃ o PostgreSQL
...
```

**Äá»‚ CHáº Y liÃªn tá»¥c** - Ä‘Ã¢y lÃ  real-time pipeline!

---

### **TERMINAL 4: BATCH JOBS (Bronze â†’ Silver â†’ Gold)**

```powershell
cd D:\2025.1\bigdata\btl_bigdata

# Äá»£i Producer/Consumer cháº¡y 30 giÃ¢y Ä‘á»ƒ cÃ³ Bronze data
Write-Host "Äá»£i Bronze data..." -ForegroundColor Yellow
Start-Sleep -Seconds 30

# 1. Silver Job (Bronze â†’ Silver)
Write-Host "`n[1/2] Running Silver Job..." -ForegroundColor Cyan
kubectl exec -n spark spark-runner -- sh -c "MINIO_ENDPOINT=http://minio.minio.svc.cluster.local:9000 MINIO_ACCESS_KEY=minioadmin MINIO_SECRET_KEY=minioadmin /opt/spark/bin/spark-submit --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262,org.postgresql:postgresql:42.7.1 /opt/project/jobs/silver_job.py --bucket house-lake --input-format json --write-postgres"

Write-Host "âœ… Silver completed!" -ForegroundColor Green

# 2. Gold Job (Silver â†’ Gold)
Write-Host "`n[2/2] Running Gold Job..." -ForegroundColor Cyan
kubectl exec -n spark spark-runner -- sh -c "MINIO_ENDPOINT=http://minio.minio.svc.cluster.local:9000 MINIO_ACCESS_KEY=minioadmin MINIO_SECRET_KEY=minioadmin /opt/spark/bin/spark-submit --packages org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262,org.postgresql:postgresql:42.7.1 /opt/project/jobs/gold_job.py --bucket house-lake --write-postgres"

Write-Host "âœ… Gold completed!" -ForegroundColor Green
Write-Host "`nğŸ‰ Batch pipeline finished!" -ForegroundColor Magenta
```

---

## ğŸ¤– BÆ¯á»šC 5: ML Pipeline (Optional)

```powershell
# 5.1. Train Model
kubectl apply -f spark/house-price-train-job.yaml
kubectl wait --for=condition=complete -n spark job/house-price-train --timeout=600s
kubectl logs -n spark job/house-price-train --tail=50

# 5.2. Start Inference CronJob
kubectl apply -f spark/house-price-inference-cronjob.yaml

# 5.3. Trigger manual inference
kubectl create job -n spark house-price-inference-manual --from=cronjob/house-price-inference
kubectl wait --for=condition=complete -n spark job/house-price-inference-manual --timeout=600s
kubectl logs -n spark job/house-price-inference-manual --tail=50
```

---

## ğŸ“Š BÆ¯á»šC 6: Verify Data

### 6.1. Check MinIO (Browser)

URL: `http://localhost:9001` (minioadmin/minioadmin)

**Expected folders in `house-lake`:**
- âœ… `bronze/dt=2026-01-16/...` - Raw data tá»« Kafka
- âœ… `silver/` - Cleaned data
- âœ… `gold/location_stats/`, `gold/year_trend/` - Aggregations
- âœ… `models/house_price/latest/` - ML model (náº¿u Ä‘Ã£ train)

---

### 6.2. Check PostgreSQL

```powershell
# Terminal má»›i - Port-forward
kubectl -n postgres port-forward svc/postgres 5433:5432
```

**Connect DBeaver:**
- Host: `localhost`
- Port: **5433**
- Database: `house_warehouse`
- User/Pass: `postgres` / `postgres`

**Run SQL:**

```sql
-- Speed Layer (Real-time tá»« Streaming)
SELECT COUNT(*) FROM house_data_speed;
SELECT * FROM house_data_speed ORDER BY created_at DESC LIMIT 10;

-- Batch Layer (tá»« Silver job)
SELECT COUNT(*) FROM fact_house;
SELECT location, COUNT(*) FROM fact_house GROUP BY location;

-- Gold Layer (Aggregations)
SELECT * FROM gold_location_stats ORDER BY avg_price DESC LIMIT 5;
SELECT * FROM gold_year_trend ORDER BY year_built DESC LIMIT 5;

-- ML Predictions (náº¿u Ä‘Ã£ cháº¡y)
SELECT COUNT(*), run_id FROM house_price_predictions GROUP BY run_id;
```

---

## ğŸ›‘ BÆ¯á»šC 7: Stop Pipelines

```powershell
# Stop Producer (Ctrl+C in Terminal 1)
# Stop Consumer (Ctrl+C in Terminal 2)  
# Stop Streaming (Ctrl+C in Terminal 3)

# Stop ML CronJob
kubectl delete cronjob -n spark house-price-inference

# Scale down (optional)
kubectl scale -n kafka deploy/producer-data --replicas=0
kubectl scale -n kafka deploy/consumer-logger --replicas=0
kubectl scale -n kafka deploy/spark-streaming --replicas=0
```

---

## ğŸ“ˆ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DATA SOURCE                           â”‚
â”‚              Producer â†’ Kafka (data-stream)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SPEED LAYER   â”‚      â”‚  BATCH LAYER       â”‚
â”‚  (Real-time)   â”‚      â”‚  (High Accuracy)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Kafka          â”‚      â”‚ Consumer           â”‚
â”‚   â†“            â”‚      â”‚   â†“                â”‚
â”‚ Spark Stream   â”‚      â”‚ Bronze (MinIO)     â”‚
â”‚   â†“            â”‚      â”‚   â†“                â”‚
â”‚ PostgreSQL     â”‚      â”‚ Silver Job         â”‚
â”‚ house_data_    â”‚      â”‚   â†“                â”‚
â”‚ speed          â”‚      â”‚ Silver (MinIO+PG)  â”‚
â”‚                â”‚      â”‚   â†“                â”‚
â”‚ Latency: <10s  â”‚      â”‚ Gold Job           â”‚
â”‚                â”‚      â”‚   â†“                â”‚
â”‚                â”‚      â”‚ Gold (MinIO+PG)    â”‚
â”‚                â”‚      â”‚   â†“                â”‚
â”‚                â”‚      â”‚ ML Train           â”‚
â”‚                â”‚      â”‚   â†“                â”‚
â”‚                â”‚      â”‚ ML Inference       â”‚
â”‚                â”‚      â”‚                    â”‚
â”‚                â”‚      â”‚ Latency: hours     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   SERVING LAYER       â”‚
         â”‚   PostgreSQL          â”‚
         â”‚   - house_data_speed  â”‚
         â”‚   - fact_house        â”‚
         â”‚   - gold_*            â”‚
         â”‚   - predictions       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› Troubleshooting

### Producer khÃ´ng gá»­i Ä‘Æ°á»£c message
```powershell
kubectl logs -n kafka -l app=producer --tail=50
# Check Kafka connection
```

### Consumer khÃ´ng ghi Ä‘Æ°á»£c MinIO
```powershell
kubectl logs -n kafka -l app=consumer --tail=50
# Check MinIO bucket tá»“n táº¡i
```

### Silver job lá»—i "Path not found"
```powershell
# Äáº£m báº£o Consumer Ä‘Ã£ cháº¡y vÃ  upload Bronze
# Check MinIO console xem cÃ³ bronze/ folder
```

### Spark Streaming khÃ´ng ghi PostgreSQL
```powershell
kubectl logs -n kafka -l app=spark-streaming --tail=100
# Check PostgreSQL connection
```

---

## ğŸ¯ Success Criteria

âœ… **Speed Pipeline (Real-time):**
- Producer gá»­i messages vÃ o Kafka
- Spark Streaming Ä‘á»c vÃ  ghi PostgreSQL
- `house_data_speed` table tÄƒng real-time
- Latency: < 10 seconds

âœ… **Batch Pipeline (Accuracy):**
- Consumer ghi Bronze vÃ o MinIO
- Silver job táº¡o cleaned data
- Gold job táº¡o aggregations
- PostgreSQL cÃ³ `fact_house` vÃ  `gold_*` tables
- Latency: minutes

âœ… **ML Pipeline:**
- Model trained vÃ  saved vÃ o MinIO
- Predictions generated vÃ  saved
- PostgreSQL cÃ³ `house_price_predictions`

---

## ğŸ“ Notes

- **First run:** Bronze â†’ Silver â†’ Gold â†’ ML Train â†’ Inference
- **Incremental runs:** Chá»‰ cháº¡y Silver (sáº½ process record má»›i), sau Ä‘Ã³ Gold, Inference
- **Full refresh:** Delete MinIO folders vÃ  PostgreSQL tables, cháº¡y láº¡i tá»« Ä‘áº§u
- **Performance:** Producer rate ~100-200 msg/batch, Consumer batch size 200

**Happy Data Engineering! ğŸš€**
