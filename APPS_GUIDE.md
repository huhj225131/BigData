# ğŸ“Š Dashboard & AI Predictor - HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng

## ğŸš€ Quick Start

### **Cháº¡y Cáº£ 2 Apps CÃ¹ng LÃºc (Khuyáº¿n Nghá»‹)**

```powershell
.\run_all_apps.ps1
```

**URLs:**
- ğŸ“Š **Dashboard PhÃ¢n TÃ­ch:** http://localhost:8501
- ğŸ¤– **AI Dá»± ÄoÃ¡n GiÃ¡:** http://localhost:8502

### **Cháº¡y Tá»«ng App RiÃªng**

```powershell
# Chá»‰ cháº¡y Dashboard
streamlit run dashboard.py --server.port 8501

# Chá»‰ cháº¡y AI Predictor
.\run_predictor.ps1
# hoáº·c: streamlit run predict_app.py --server.port 8502
```

---

## ğŸ“Š Dashboard PhÃ¢n TÃ­ch (dashboard.py)

### **Chá»©c NÄƒng:**

âœ… **Lambda Architecture:** Merge Speed Layer + Batch Layer
âœ… **Real-time Data:** Hiá»ƒn thá»‹ dá»¯ liá»‡u tá»« Kafka trong <10s
âœ… **Gold Analytics:** 4 báº£ng phÃ¢n tÃ­ch tá»« Spark
âœ… **ML Predictions:** Xem káº¿t quáº£ dá»± Ä‘oÃ¡n tá»« model

### **Tabs:**

1. **ğŸ“ PhÃ¢n tÃ­ch vÃ¹ng** - GiÃ¡ theo khu vá»±c, heatmap, pie chart
2. **ğŸ“ˆ Xu hÆ°á»›ng thá»‹ trÆ°á»ng** - GiÃ¡ theo tháº­p ká»·, phÃ¢n tÃ­ch tÃ¬nh tráº¡ng
3. **ğŸ›ï¸ PhÃ¢n tÃ­ch phÃ²ng ngá»§** - GiÃ¡ theo sá»‘ phÃ²ng ngá»§
4. **ğŸ  Chi tiáº¿t BÄS** - Scatter plot, danh sÃ¡ch BÄS
5. **âš¡ Speed vs Batch** - So sÃ¡nh 2 layers

### **Data Sources:**

- **Speed Layer:** `house_data_speed` (real-time tá»« Spark Streaming)
- **Batch Layer:** `fact_house` (tá»« Spark Silver job)
- **Gold Layer:** 4 báº£ng aggregations
  - `gold_location_stats`
  - `gold_condition_stats`
  - `gold_bedroom_analysis`
  - `gold_year_built_trends`
- **ML Layer:** `house_price_predictions`

### **Bá»™ Lá»c (Sidebar):**

- ğŸšï¸ Nguá»“n dá»¯ liá»‡u: Speed Only / Batch Only / Merge
- ğŸ“ Khu vá»±c
- ğŸ·ï¸ TÃ¬nh tráº¡ng nhÃ 
- ğŸ’° Khoáº£ng giÃ¡

---

## ğŸ¤– AI Dá»± ÄoÃ¡n GiÃ¡ (predict_app.py)

### **Chá»©c NÄƒng:**

âœ… **Input Ä‘Æ¡n giáº£n:** Chá»‰ cáº§n 6 thÃ´ng tin cÆ¡ báº£n
âœ… **Feature Engineering tá»± Ä‘á»™ng:** TÃ­nh 4 features nhÆ° Spark
âœ… **Káº¿t quáº£ chi tiáº¿t:** GiÃ¡ dá»± Ä‘oÃ¡n + breakdown + confidence interval
âœ… **Lá»‹ch sá»­:** LÆ°u 10 dá»± Ä‘oÃ¡n gáº§n nháº¥t

### **CÃ¡ch DÃ¹ng:**

**BÆ°á»›c 1:** Nháº­p thÃ´ng tin (form bÃªn trÃ¡i)
- Diá»‡n tÃ­ch (sqft): 100 - 10,000
- PhÃ²ng ngá»§: 0 - 10
- PhÃ²ng táº¯m: 0 - 10
- NÄƒm xÃ¢y dá»±ng: 1800 - 2026
- Khu vá»±c: Downtown, Suburb, Rural...
- TÃ¬nh tráº¡ng: Excellent, Good, Fair, Poor

**BÆ°á»›c 2:** Nháº¥n **"ğŸ”® Dá»± ÄoÃ¡n GiÃ¡"**

**BÆ°á»›c 3:** Xem káº¿t quáº£ (bÃªn pháº£i)
- ğŸ’° GiÃ¡ dá»± Ä‘oÃ¡n
- ğŸ”§ Features tá»± Ä‘á»™ng: house_age, total_rooms, condition_score
- ğŸ“Š Breakdown áº£nh hÆ°á»Ÿng tá»«ng yáº¿u tá»‘
- ğŸ“ˆ Khoáº£ng tin cáº­y (Â±10%)

### **Features Tá»± Äá»™ng:**

```python
house_age = 2026 - year_built
total_rooms = bedrooms + bathrooms
condition_score = {'Excellent': 3, 'Good': 2, 'Fair': 1, 'Poor': 0}
price_per_sqft = predicted_price / sqft
```

### **Model:**

- **Hiá»‡n táº¡i:** Mock prediction (heuristic-based) - cho káº¿t quáº£ há»£p lÃ½ Ä‘á»ƒ demo
- **Äá»ƒ dÃ¹ng model thá»±c:** Copy file `house_price_model.pkl` vÃ o thÆ° má»¥c root â†’ app tá»± Ä‘á»™ng load

---

## ğŸ“¦ CÃ i Äáº·t Dependencies

```powershell
pip install -r requirements.txt
```

Hoáº·c cÃ i thá»§ cÃ´ng:

```powershell
pip install streamlit pandas numpy psycopg2-binary altair scikit-learn
```

---

## ğŸ”§ Káº¿t Ná»‘i Database

### **PostgreSQL (Dashboard):**

Set environment variables hoáº·c máº·c Ä‘á»‹nh:

```powershell
$env:DB_HOST = "localhost"
$env:DB_PORT = "5433"
$env:DB_NAME = "house_warehouse"
$env:DB_USER = "postgres"
$env:DB_PASSWORD = "postgres"
```

### **Port-forward Postgres:**

```powershell
kubectl -n postgres port-forward svc/postgres 5433:5432
```

---

## ğŸ¨ Customization

### **ThÃªm Location Má»›i (AI Predictor):**

File: `predict_app.py`, tÃ¬m dÃ²ng `location = st.selectbox`

```python
location = st.selectbox(
    "ğŸ“ Khu vá»±c",
    options=['Downtown', 'Suburb', 'YourNewLocation'],  # ThÃªm á»Ÿ Ä‘Ã¢y
)

# Cáº­p nháº­t giÃ¡ base
location_multiplier = {
    'Downtown': 400,
    'YourNewLocation': 350,  # ThÃªm á»Ÿ Ä‘Ã¢y
}
```

### **Thay Äá»•i Auto-refresh (Dashboard):**

File: `dashboard.py`, cuá»‘i file:

```python
if auto_refresh:
    time.sleep(5)  # Thay Ä‘á»•i giÃ¢y á»Ÿ Ä‘Ã¢y
    st.rerun()
```

---

## ğŸ› Troubleshooting

### **Port Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng:**

```powershell
# Äá»•i port
streamlit run dashboard.py --server.port 8503
streamlit run predict_app.py --server.port 8504
```

### **KhÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c Database:**

```powershell
# Check port-forward Ä‘ang cháº¡y
kubectl -n postgres get pods
kubectl -n postgres port-forward svc/postgres 5433:5432

# Test káº¿t ná»‘i
Test-NetConnection localhost -Port 5433
```

### **Dashboard khÃ´ng cÃ³ dá»¯ liá»‡u:**

- âœ… Check Spark jobs Ä‘Ã£ cháº¡y: `kubectl get jobs -n spark`
- âœ… Check PostgreSQL cÃ³ data: DBeaver â†’ `SELECT COUNT(*) FROM fact_house`
- âœ… Check MinIO cÃ³ data: http://localhost:9001

### **AI Predictor khÃ´ng cháº¡y:**

- âš ï¸ Äang dÃ¹ng mock prediction - váº«n work bÃ¬nh thÆ°á»ng
- ğŸ’¡ Äá»ƒ dÃ¹ng model thá»±c, xem pháº§n **Model** á»Ÿ trÃªn

---

## ğŸ“ File Structure

```
btl_bigdata/
â”œâ”€â”€ dashboard.py              # Dashboard phÃ¢n tÃ­ch chÃ­nh
â”œâ”€â”€ predict_app.py            # AI predictor Ä‘á»™c láº­p
â”œâ”€â”€ run_all_apps.ps1          # Cháº¡y cáº£ 2 apps
â”œâ”€â”€ run_predictor.ps1         # Cháº¡y riÃªng predictor
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ APPS_GUIDE.md            # File nÃ y
â”œâ”€â”€ kafka/                    # Kafka components
â”œâ”€â”€ spark/                    # Spark jobs
â”œâ”€â”€ postgres/                 # PostgreSQL configs
â””â”€â”€ minio/                    # MinIO configs
```

---

## ğŸ“¸ Preview

### **Dashboard:**

- KPIs: Sá»‘ BÄS, giÃ¡ TB, diá»‡n tÃ­ch TB, tá»•ng giÃ¡ trá»‹
- Real-time feed: 20 records má»›i nháº¥t tá»« Speed Layer
- Charts: Heatmap, pie, bar, line, scatter
- ML Results: Actual vs Predicted

### **AI Predictor:**

- Form input: Clean, validated
- Results card: Large price display
- Features breakdown: 4 cards
- Price analysis: Table breakdown
- History: Last 10 predictions

---

## ğŸš€ Production Tips

1. **Database Connection Pooling:** Sá»­ dá»¥ng `psycopg2.pool` thay vÃ¬ connect má»—i láº§n
2. **Cache Strategy:** TÄƒng TTL náº¿u data khÃ´ng thay Ä‘á»•i thÆ°á»ng xuyÃªn
3. **Load Model Once:** Model Ä‘Ã£ Ä‘Æ°á»£c cache vá»›i `@st.cache_resource`
4. **Environment Variables:** DÃ¹ng `.env` file cho production

---

## ğŸ“ Support

- **Pipeline Setup:** Xem [QUICK_START.md](QUICK_START.md)
- **Spark Jobs:** Xem [README.md](README.md)
- **Issues:** Check logs vá»›i `kubectl logs` hoáº·c Streamlit console

---

**Happy Data Analyzing! ğŸ“ŠğŸ¤–**
